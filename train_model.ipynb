{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1d24533",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import string\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "train_path = r\"D:\\Amazon ML\\student_resource\\dataset\\train.csv\"\n",
    "test_path = r\"D:\\Amazon ML\\student_resource\\dataset\\test.csv\"\n",
    "sample_test_path = r\"D:\\Amazon ML\\student_resource\\dataset\\sample_test.csv\"\n",
    "sample_out_path = r\"D:\\Amazon ML\\student_resource\\dataset\\sample_test_out.csv\"\n",
    "\n",
    "train = pd.read_csv(train_path)\n",
    "test = pd.read_csv(test_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ff8f4c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74999/74999 [00:04<00:00, 18442.90it/s]\n",
      "100%|██████████| 75000/75000 [00:03<00:00, 18917.10it/s]\n"
     ]
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"http\\S+|www\\S+\", \"\", text)\n",
    "    text = re.sub(r\"<.*?>\", \"\", text)\n",
    "    text = re.sub(r\"[^a-z0-9\\s.,-]\", \" \", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text\n",
    "\n",
    "train[\"clean_text\"] = train[\"catalog_content\"].progress_apply(clean_text)\n",
    "test[\"clean_text\"] = test[\"catalog_content\"].progress_apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06c948d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74999/74999 [00:02<00:00, 25413.12it/s]\n",
      "100%|██████████| 75000/75000 [00:02<00:00, 26039.97it/s]\n"
     ]
    }
   ],
   "source": [
    "def extract_quantity(text):\n",
    "    if not isinstance(text, str):\n",
    "        return 1\n",
    "    patterns = [\n",
    "        r\"pack of (\\d+)\",\n",
    "        r\"set of (\\d+)\",\n",
    "        r\"(\\d+)\\s?pcs?\",\n",
    "        r\"(\\d+)\\s?x\",\n",
    "        r\"(\\d+)\\s?count\",\n",
    "        r\"(\\d+)\\s?piece\"\n",
    "    ]\n",
    "    for p in patterns:\n",
    "        m = re.search(p, text)\n",
    "        if m:\n",
    "            return int(m.group(1))\n",
    "    return 1\n",
    "\n",
    "train[\"item_quantity\"] = train[\"clean_text\"].progress_apply(extract_quantity)\n",
    "test[\"item_quantity\"] = test[\"clean_text\"].progress_apply(extract_quantity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79ba9e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train price summary:\n",
      "count    74999.000000\n",
      "mean        23.647953\n",
      "std         33.377054\n",
      "min          0.130000\n",
      "25%          6.797500\n",
      "50%         14.000000\n",
      "75%         28.625000\n",
      "max       2796.000000\n",
      "Name: price, dtype: float64\n",
      "\n",
      "Top quantities:\n",
      "item_quantity\n",
      "1       50121\n",
      "6        4871\n",
      "12       4348\n",
      "2        2758\n",
      "3        2368\n",
      "4        2174\n",
      "24       1225\n",
      "8        1006\n",
      "10        659\n",
      "5         582\n",
      "20        399\n",
      "18        319\n",
      "16        246\n",
      "100       243\n",
      "40        227\n",
      "48        209\n",
      "15        205\n",
      "36        197\n",
      "50        175\n",
      "30        173\n",
      "60        157\n",
      "9         154\n",
      "7         137\n",
      "72        124\n",
      "96        124\n",
      "25        112\n",
      "14        110\n",
      "80        102\n",
      "32         78\n",
      "200        71\n",
      "22         68\n",
      "120        61\n",
      "42         44\n",
      "130        41\n",
      "65         40\n",
      "90         38\n",
      "150        38\n",
      "28         31\n",
      "84         31\n",
      "1000       30\n",
      "500        27\n",
      "64         27\n",
      "75         27\n",
      "240        26\n",
      "180        26\n",
      "70         26\n",
      "11         26\n",
      "108        25\n",
      "35         24\n",
      "13         23\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Train price summary:\")\n",
    "print(train[\"price\"].describe())\n",
    "\n",
    "print(\"\\nTop quantities:\")\n",
    "print(train[\"item_quantity\"].value_counts().head(50))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "697703b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cleaned data saved.\n"
     ]
    }
   ],
   "source": [
    "clean_train_path = r\"D:\\Amazon ML\\student_resource\\dataset\\train_clean.csv\"\n",
    "clean_test_path = r\"D:\\Amazon ML\\student_resource\\dataset\\test_clean.csv\"\n",
    "\n",
    "train.to_csv(clean_train_path, index=False)\n",
    "test.to_csv(clean_test_path, index=False)\n",
    "print(\"✅ Cleaned data saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b93f2147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "CUDA device count: 1\n",
      "CUDA device name: NVIDIA GeForce RTX 3050 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"CUDA device count:\", torch.cuda.device_count())\n",
    "print(\"CUDA device name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"None\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "426e9913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "train = pd.read_csv(r\"D:\\Amazon ML\\student_resource\\dataset\\train_clean.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "867a12c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59999, 6) (15000, 6)\n"
     ]
    }
   ],
   "source": [
    "train_data, val_data = train_test_split(train, test_size=0.2, random_state=42)\n",
    "print(train_data.shape, val_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdc4de4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "y_train = np.log1p(train_data[\"price\"].values)  # log(price + 1)\n",
    "y_val = np.log1p(val_data[\"price\"].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e847efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating train embeddings...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baafe59a1e554d89bd6640d58c6eb0b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating validation embeddings...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b842006cac384f47a75573867a382664",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/235 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train embeddings shape: (59999, 768)\n",
      "Validation embeddings shape: (15000, 768)\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "# Initialize model on GPU\n",
    "model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2', device='cuda')\n",
    "\n",
    "# Encode train and validation texts\n",
    "train_texts = train_data[\"clean_text\"].tolist()\n",
    "val_texts = val_data[\"clean_text\"].tolist()\n",
    "\n",
    "# Generate embeddings\n",
    "print(\"Generating train embeddings...\")\n",
    "train_embeddings = model.encode(train_texts, batch_size=64, show_progress_bar=True, device='cuda')\n",
    "\n",
    "print(\"Generating validation embeddings...\")\n",
    "val_embeddings = model.encode(val_texts, batch_size=64, show_progress_bar=True, device='cuda')\n",
    "\n",
    "# Convert to numpy arrays\n",
    "X_train_bert = np.array(train_embeddings)\n",
    "X_val_bert = np.array(val_embeddings)\n",
    "\n",
    "print(\"Train embeddings shape:\", X_train_bert.shape)\n",
    "print(\"Validation embeddings shape:\", X_val_bert.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "227c4821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Text embeddings saved.\n"
     ]
    }
   ],
   "source": [
    "np.save(r\"D:\\Amazon ML\\student_resource\\dataset\\train_text_embeds.npy\", X_train_bert)\n",
    "np.save(r\"D:\\Amazon ML\\student_resource\\dataset\\val_text_embeds.npy\", X_val_bert)\n",
    "\n",
    "print(\"✅ Text embeddings saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71d510d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.229071 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 195840\n",
      "[LightGBM] [Info] Number of data points in the train set: 59999, number of used features: 768\n",
      "[LightGBM] [Info] Start training from score 2.738616\n",
      "LGBMRegressor SMAPE on validation: 58.56%\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "X_train = np.array(train_embeddings)\n",
    "X_val = np.array(val_embeddings)\n",
    "\n",
    "# Initialize model\n",
    "model = LGBMRegressor(\n",
    "    objective='regression',\n",
    "    boosting_type='gbdt',\n",
    "    learning_rate=0.05,\n",
    "    num_leaves=64,\n",
    "    max_depth=10,\n",
    "    n_estimators=1000,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train with early stopping\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    eval_metric='mae',\n",
    "    \n",
    ")\n",
    "\n",
    "# Predict\n",
    "val_preds_log = model.predict(X_val)\n",
    "val_preds = np.expm1(val_preds_log)\n",
    "val_true = np.expm1(y_val)  # make sure targets are back to original scale\n",
    "\n",
    "# SMAPE\n",
    "smape = np.mean(np.abs(val_preds - val_true) / ((np.abs(val_preds) + np.abs(val_true))/2)*100) \n",
    "print(f\"LGBMRegressor SMAPE on validation: {smape:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11131ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import transforms, models\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "493326fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/efficientnet_b3_rwightman-b3899882.pth\" to C:\\Users\\rames/.cache\\torch\\hub\\checkpoints\\efficientnet_b3_rwightman-b3899882.pth\n",
      "100%|██████████| 47.2M/47.2M [00:02<00:00, 16.7MB/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import models, transforms\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load pretrained EfficientNet-B3\n",
    "efficientnet = models.efficientnet_b3(weights='IMAGENET1K_V1')  # new API\n",
    "efficientnet = efficientnet.to(device)\n",
    "efficientnet.eval()  # set to evaluation mode\n",
    "\n",
    "# Remove classifier to get embeddings (keep avgpool)\n",
    "feature_extractor = torch.nn.Sequential(\n",
    "    efficientnet.features,\n",
    "    efficientnet.avgpool\n",
    ")\n",
    "\n",
    "# Image preprocessing\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "565199dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "def get_image_embeddings(img_paths, batch_size=32):\n",
    "    embeddings = []\n",
    "\n",
    "    for i in tqdm(range(0, len(img_paths), batch_size), desc=\"Extracting embeddings\"):\n",
    "        batch_imgs = []\n",
    "        # ---- Load and preprocess images ----\n",
    "        for img_path in img_paths[i:i+batch_size]:\n",
    "            try:\n",
    "                img = Image.open(img_path).convert('RGB')\n",
    "                img = transform(img)\n",
    "            except Exception as e:\n",
    "                # Handle missing or corrupted files safely\n",
    "                print(f\"Warning: could not process {img_path}: {e}\")\n",
    "                img = torch.zeros(3, 224, 224)\n",
    "            batch_imgs.append(img)\n",
    "\n",
    "        # ---- Batch forward pass ----\n",
    "        batch_tensor = torch.stack(batch_imgs).to(device)\n",
    "        with torch.no_grad():\n",
    "            batch_features = feature_extractor(batch_tensor)\n",
    "            batch_features = torch.flatten(batch_features, 1)  # cleaner flatten\n",
    "            embeddings.append(batch_features.cpu().numpy())\n",
    "\n",
    "        # (Optional) free GPU memory\n",
    "        del batch_tensor, batch_features\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    return np.vstack(embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14376a84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting train image embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings: 100%|██████████| 1875/1875 [48:49<00:00,  1.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting validation image embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings: 100%|██████████| 469/469 [12:08<00:00,  1.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train image embeddings shape: (59999, 1536)\n",
      "Validation image embeddings shape: (15000, 1536)\n",
      "✅ Image embeddings saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "train_img_folder = r\"D:\\Amazon ML\\student_resource\\dataset\\images\\train\"\n",
    "val_img_folder = r\"D:\\Amazon ML\\student_resource\\dataset\\images\\train\"  # same folder\n",
    "\n",
    "# Build image paths\n",
    "train_img_paths = [\n",
    "    os.path.join(train_img_folder, f\"{sid}.jpg\") for sid in train_data[\"sample_id\"]\n",
    "]\n",
    "val_img_paths = [\n",
    "    os.path.join(val_img_folder, f\"{sid}.jpg\") for sid in val_data[\"sample_id\"]\n",
    "]\n",
    "\n",
    "# --- Extract embeddings ---\n",
    "print(\"Extracting train image embeddings...\")\n",
    "X_train_img = get_image_embeddings(train_img_paths, batch_size=32)\n",
    "\n",
    "print(\"Extracting validation image embeddings...\")\n",
    "X_val_img = get_image_embeddings(val_img_paths, batch_size=32)\n",
    "\n",
    "# --- Verify shapes ---\n",
    "print(f\"Train image embeddings shape: {X_train_img.shape}\")\n",
    "print(f\"Validation image embeddings shape: {X_val_img.shape}\")\n",
    "\n",
    "# --- Save embeddings ---\n",
    "os.makedirs(r\"D:\\Amazon ML\\student_resource\\dataset\", exist_ok=True)\n",
    "np.save(r\"D:\\Amazon ML\\student_resource\\dataset\\train_image_embeds.npy\", X_train_img)\n",
    "np.save(r\"D:\\Amazon ML\\student_resource\\dataset\\val_image_embeds.npy\", X_val_img)\n",
    "\n",
    "print(\"✅ Image embeddings saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e5d3e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_final = np.hstack([X_train_bert, X_train_img, train_data[\"item_quantity\"].values.reshape(-1,1)])\n",
    "X_val_final = np.hstack([X_val_bert, X_val_img, val_data[\"item_quantity\"].values.reshape(-1,1)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37405823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Targets (log-transform)\n",
    "y_train_log = np.log1p(train_data[\"price\"].values)\n",
    "y_val_log = np.log1p(val_data[\"price\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "35e5d33c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 587648\n",
      "[LightGBM] [Info] Number of data points in the train set: 59999, number of used features: 2305\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 2305 dense feature groups (132.06 MB) transferred to GPU in 0.050661 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 2.738616\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMRegressor(colsample_bytree=0.8, device=&#x27;gpu&#x27;, learning_rate=0.01,\n",
       "              max_depth=12, n_estimators=2500, num_leaves=64,\n",
       "              objective=&#x27;regression&#x27;, random_state=42, subsample=0.8)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;LGBMRegressor<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LGBMRegressor(colsample_bytree=0.8, device=&#x27;gpu&#x27;, learning_rate=0.01,\n",
       "              max_depth=12, n_estimators=2500, num_leaves=64,\n",
       "              objective=&#x27;regression&#x27;, random_state=42, subsample=0.8)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LGBMRegressor(colsample_bytree=0.8, device='gpu', learning_rate=0.01,\n",
       "              max_depth=12, n_estimators=2500, num_leaves=64,\n",
       "              objective='regression', random_state=42, subsample=0.8)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "import numpy as np\n",
    "\n",
    "# Initialize model (GPU-enabled)\n",
    "model = LGBMRegressor(\n",
    "    objective='regression',\n",
    "    boosting_type='gbdt',\n",
    "    learning_rate=0.01,\n",
    "    num_leaves=64,\n",
    "    max_depth=12,\n",
    "    n_estimators=2500,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    device='gpu'\n",
    ")\n",
    "\n",
    "# Train with early stopping\n",
    "model.fit(\n",
    "    X_train_final, y_train_log,\n",
    "    eval_set=[(X_val_final, y_val_log)],\n",
    "    eval_metric='mae',\n",
    "   \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b312d7fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multimodal LightGBM SMAPE on validation: 0.57\n"
     ]
    }
   ],
   "source": [
    "# Predict\n",
    "val_preds_log = model.predict(X_val_final)\n",
    "val_preds = np.expm1(val_preds_log)  # back to original price scale\n",
    "val_true = val_data[\"price\"].values\n",
    "\n",
    "# Compute SMAPE\n",
    "smape = np.mean(np.abs(val_preds - val_true) / ((np.abs(val_preds) + np.abs(val_true))/2)) \n",
    "print(f\"Multimodal LightGBM SMAPE on validation: {smape:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b92e3016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Multimodal LightGBM model saved\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(model, r\"D:\\Amazon ML\\student_resource\\dataset\\lgbm_multimodal_model.pkl\")\n",
    "print(\"✅ Multimodal LightGBM model saved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b2c13ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def clean_text(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"http\\S+|www\\S+\", \"\", text)\n",
    "    text = re.sub(r\"<.*?>\", \"\", text)\n",
    "    text = re.sub(r\"[^a-z0-9\\s.,-]\", \" \", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text\n",
    "def extract_quantity(text):\n",
    "    if not isinstance(text, str):\n",
    "        return 1\n",
    "    patterns = [\n",
    "        r\"pack of (\\d+)\",\n",
    "        r\"set of (\\d+)\",\n",
    "        r\"(\\d+)\\s?pcs?\",\n",
    "        r\"(\\d+)\\s?x\",\n",
    "        r\"(\\d+)\\s?count\",\n",
    "        r\"(\\d+)\\s?piece\"\n",
    "    ]\n",
    "    for p in patterns:\n",
    "        m = re.search(p, text)\n",
    "        if m:\n",
    "            return int(m.group(1))\n",
    "    return 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "42734f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 10881.30it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 14952.42it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53967b5909f8467db9031a87cb53eefe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings: 100%|██████████| 4/4 [00:05<00:00,  1.36s/it]\n"
     ]
    }
   ],
   "source": [
    "# Load sample test and output\n",
    "sample_test = pd.read_csv(r\"D:\\Amazon ML\\student_resource\\dataset\\sample_test.csv\")\n",
    "sample_test_out = pd.read_csv(r\"D:\\Amazon ML\\student_resource\\dataset\\sample_test_out.csv\")\n",
    "\n",
    "\n",
    "# Apply to sample_test\n",
    "sample_test[\"clean_text\"] = sample_test[\"catalog_content\"].progress_apply(clean_text)\n",
    "sample_test[\"item_quantity\"] = sample_test[\"clean_text\"].progress_apply(extract_quantity)\n",
    "\n",
    "# Extract features\n",
    "# Text embeddings\n",
    "sample_test_texts = sample_test[\"clean_text\"].tolist()\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load a sentence transformer model\n",
    "embedding_model = SentenceTransformer('all-mpnet-base-v2', device='cuda')\n",
    "\n",
    "# Encode text\n",
    "X_sample_text = embedding_model.encode(sample_test_texts, batch_size=64, show_progress_bar=True, device='cuda')\n",
    "\n",
    "\n",
    "# Image embeddings\n",
    "sample_img_folder = r\"D:\\Amazon ML\\student_resource\\dataset\\images\\sample_test\"\n",
    "sample_img_paths = [os.path.join(sample_img_folder, f\"{sid}.jpg\") for sid in sample_test[\"sample_id\"]]\n",
    "X_sample_img = get_image_embeddings(sample_img_paths, batch_size=32)\n",
    "\n",
    "# Combine embeddings + numeric\n",
    "X_sample_final = np.hstack([\n",
    "    X_sample_text,\n",
    "    X_sample_img,\n",
    "    sample_test[\"item_quantity\"].values.reshape(-1,1)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "923cc7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Load trained multimodal LightGBM\n",
    "model = joblib.load(r\"D:\\Amazon ML\\student_resource\\dataset\\lgbm_multimodal_model.pkl\")\n",
    "\n",
    "# Predict (log scale → back to original)\n",
    "sample_preds_log = model.predict(X_sample_final)\n",
    "sample_preds = np.expm1(sample_preds_log)  # this is your actual predicted price array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eec27f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multimodal LightGBM SMAPE on sample_test: 104.81%\n"
     ]
    }
   ],
   "source": [
    "# True prices\n",
    "y_true = sample_test_out[\"price\"].values\n",
    "\n",
    "# Predicted prices\n",
    "y_pred = sample_preds  # from previous step\n",
    "\n",
    "# Compute SMAPE\n",
    "smape = np.mean(np.abs(y_pred - y_true) / ((np.abs(y_pred) + np.abs(y_true))/2)*100) \n",
    "print(f\"Multimodal LightGBM SMAPE on sample_test: {smape:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2e3096fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75000/75000 [00:03<00:00, 20644.49it/s]\n",
      "100%|██████████| 75000/75000 [00:02<00:00, 26415.61it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a214261b51e47608ddaa137a1fee45e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1172 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  56%|█████▌    | 1313/2344 [34:51<27:57,  1.63s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: could not process D:\\Amazon ML\\student_resource\\dataset\\images\\test\\286800.jpg: [Errno 2] No such file or directory: 'D:\\\\Amazon ML\\\\student_resource\\\\dataset\\\\images\\\\test\\\\286800.jpg'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings: 100%|██████████| 2344/2344 [1:01:50<00:00,  1.58s/it]\n"
     ]
    }
   ],
   "source": [
    "# Load sample test and output\n",
    "test_clean = pd.read_csv(r\"D:\\Amazon ML\\student_resource\\dataset\\test_clean.csv\")\n",
    "\n",
    "\n",
    "# Apply to sample_test\n",
    "test_clean[\"clean_text\"] = test_clean[\"catalog_content\"].progress_apply(clean_text)\n",
    "test_clean[\"item_quantity\"] = test_clean[\"clean_text\"].progress_apply(extract_quantity)\n",
    "\n",
    "# Extract features\n",
    "# Text embeddings\n",
    "test_clean_texts = test_clean[\"clean_text\"].tolist()\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load a sentence transformer model\n",
    "embedding_model = SentenceTransformer('all-mpnet-base-v2', device='cuda')\n",
    "\n",
    "# Encode text\n",
    "X_sample_text = embedding_model.encode(test_clean_texts, batch_size=64, show_progress_bar=True, device='cuda')\n",
    "\n",
    "\n",
    "# Image embeddings\n",
    "test_img_folder = r\"D:\\Amazon ML\\student_resource\\dataset\\images\\test\"\n",
    "test_img_paths = [os.path.join(test_img_folder, f\"{sid}.jpg\") for sid in test_clean[\"sample_id\"]]\n",
    "X_sample_img = get_image_embeddings(test_img_paths, batch_size=32)\n",
    "\n",
    "# Combine embeddings + numeric\n",
    "X_sample_final = np.hstack([\n",
    "    X_sample_text,\n",
    "    X_sample_img,\n",
    "    test_clean[\"item_quantity\"].values.reshape(-1,1)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e66dec50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Load trained multimodal LightGBM\n",
    "model = joblib.load(r\"D:\\Amazon ML\\student_resource\\dataset\\lgbm_multimodal_model.pkl\")\n",
    "\n",
    "# Predict (log scale → back to original)\n",
    "sample_preds_log = model.predict(X_sample_final)\n",
    "sample_preds = np.expm1(sample_preds_log)  # this is your actual predicted price array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "563e4d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved predictions to: D:\\Amazon ML\\student_resource\\dataset\\test_out_1.csv\n"
     ]
    }
   ],
   "source": [
    "# Create DataFrame for submission\n",
    "submission = pd.DataFrame({\n",
    "    \"sample_id\": test_clean[\"sample_id\"],\n",
    "    \"price\": sample_preds\n",
    "})\n",
    "\n",
    "# Save to CSV\n",
    "output_path = r\"D:\\Amazon ML\\student_resource\\dataset\\test_out_1.csv\"\n",
    "submission.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"✅ Saved predictions to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "32addd31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Combined dataset saved as large_train.csv\n",
      "Total rows: 149999\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv(\"train_clean.csv\")\n",
    "test = pd.read_csv(\"test_clean.csv\")\n",
    "test_out = pd.read_csv(\"test_out.csv\")\n",
    "\n",
    "test = test.merge(test_out, on=\"sample_id\", how=\"left\")\n",
    "\n",
    "combined = pd.concat([train, test], ignore_index=True)\n",
    "combined.to_csv(\"large_train.csv\", index=False)\n",
    "\n",
    "print(\"✅ Combined dataset saved as large_train.csv\")\n",
    "print(\"Total rows:\", combined.shape[0])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
